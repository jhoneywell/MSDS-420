{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables:\n",
    "\n",
    "- Submit a single zip-compressed file that has the name: YourLastName_Exercise_1 that has the following files:\n",
    "\n",
    " 1. Your **PDF document** that has your Source code and output\n",
    " 2. Your **ipynb script** that has your Source code and output\n",
    "\n",
    "\n",
    "# Objectives:\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    " - Use Jupyter notebook to run ipynb script\n",
    " - Experiment with file processing (reading and writing files in different formats)\n",
    " - Use different data types to store and process data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Submission Formats :\n",
    "\n",
    "Create a folder or directory with all supplementary files with your last name at the beginning of the folder name, compress that folder with zip compression, and post the zip-archived folder under the assignment link in Canvas. The following files should be included in an archive folder/directory that is uploaded as a single zip-compressed file. (Use zip, not StuffIt or any 7z or any other compression method.)\n",
    "\n",
    "\n",
    "1. Complete IPYNB script that has the source code in Python used to access and analyze the data. The code should be submitted as an IPYNB script that can be be loaded and run in Jupyter Notebook for Python\n",
    "2. Output from the program, such as console listing/logs, text files, and graphics output for visualizations. If you use the Data Science Computing Cluster or School of Professional Studies database servers or systems, include Linux logs of your sessions as plain text files. Linux logs may be generated by using the script process at the beginning of your session, as demonstrated in tutorial handouts for the DSCC servers.\n",
    "3. List file names and descriptions of files in the zip-compressed folder/directory.\n",
    "\n",
    "\n",
    "Formatting Python Code\n",
    "When programming in Python, refer to Kenneth Reitz’ PEP 8: The Style Guide for Python Code:\n",
    "http://pep8.org/ (Links to an external site.)Links to an external site.\n",
    "There is the Google style guide for Python at\n",
    "https://google.github.io/styleguide/pyguide.html (Links to an external site.)Links to an external site.\n",
    "Comment often and in detail.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There are many different kinds of data to be managed and analyzed today, and there are many ways to do it using Python.   Being able to manage and modify data isn't useful unless you can also get data into Python, and save your results from it.   Beginning with this session we're going to review techniques for input and output from Python starting with the simplest file formats and some basic Python tools.  We'll also take a first look at the pandas package.  Pandas has become very popular amongst “Pythonic” data scientists and is being used at the largest of the big data firms.  In the sessions that follow we'll consider more complicated file types and data “munging” tools and techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So, let's start with flat files.  A flat file is just a file that's, well, flat.  It's typically a string of characters that may include end of line markers like a newline or carriage return code.  Let's write a simple flat file out to disk by entering the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open('myflatfile.txt','w')  # open to write to a text file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: “In [1]:” represents the command prompt in your IPython session.  Depending on what you've been doing in a session, the digit or digits you see in it will vary.  But you knew that, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='myflatfile.txt' mode='w' encoding='cp1252'>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile # outfile is an open file 'object' in write mode.  By default it's a text, not binary, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_io.TextIOWrapper"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outfile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pardon the slight digression, above.  It's purpose was to show what kind of Python 'object' outfile is.  (Everything in Python is an object, right?)  the .txt file name extension is optional.  Now, let's create a text string and then write it to outfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "iLikeButter='''Slather me toast with a bargefull of butter, and crown it with a bucket of Pythonberry jam.'''\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is obviously a quote from a high cholesterol data science pirate.  How many characters are in this string?  Try the function len(iLikeButter).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(iLikeButter)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write the string to outfile and then close outfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile.write(iLikeButter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile.close()\t\t# it's good practice to close whatever you open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jrh597\\\\MSDS 420'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's read your file back in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infile=open('myflatfile.txt','r')\t#read as a text file. For a binary, you'd use 'rb'\n",
    "doYouWantButter=infile.read()\t#reads the file contents into a string variable\n",
    "doYouWantButter\t\t\t#this should give you he iLikeButter string value\n",
    "type(doYouWantButter)\t\t# this should give you “str”\n",
    "type(_)\t\t\t\t# should have the same result as above, right?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When used as above, what does the underscore, “_”, represent?\n",
    "\n",
    "Next, let's read a text file with more than one line.  The text file louielouie.txt has been provided to you. Pop it into the default directory for your session, the directory you identified before.  Then, open it for reading:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "kingsMenLouie=open('louielouie.txt','r')\t\t#'r' since this is a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Louie Louie, oh no\\nMe gotta go\\nAye-yi-yi-yi, I said\\nLouie Louie, oh baby\\nMe gotta go\\nFine little girl waits for me\\nCatch a ship across the sea\\nSail that ship about, all alone\\nNever know if I make it home\\nLouie Louie, oh oh no\\nMe gotta go, oh no\\nLouie Louie, oh baby\\nI said we gotta go\\nThree nights and days I sail the sea\\nThink of girl, constantly\\nOn that ship, I dream she's there\\nI smell the rose in her hair.\\nLouie Louie, oh no\\nMe gotta go\\nAye-yi-yi-yi, I said\\nLouie Louie, oh baby\\nMe gotta go\\nOkay, let's give it to 'em, right now!\\nSee Jamaica, the moon above\\nIt won't be long, me see me love\\nTake her in my arms again\\nI tell her I'll never leave again\\nLouie Louie, oh no\\nMe gotta go\\nAye-yi-yi-yi, I said\\nLouie Louie, oh baby\\nMe gotta go\\nI said we gotta go now\\nLet's take it on outta here now\\nLet's go!!\\n\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louielouie=kingsMenLouie.read() \t# take a look at louielouie by typing its name\n",
    "louielouie"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "And, then you could split the lines in louielouie into a list of lines as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Louie Louie, oh no\n",
      "Me gotta go\n",
      "Aye-yi-yi-yi, I said\n",
      "Louie Louie, oh baby\n",
      "Me gotta go\n",
      "Fine little girl waits for me\n",
      "Catch a ship across the sea\n",
      "Sail that ship about, all alone\n",
      "Never know if I make it home\n",
      "Louie Louie, oh oh no\n",
      "Me gotta go, oh no\n",
      "Louie Louie, oh baby\n",
      "I said we gotta go\n",
      "Three nights and days I sail the sea\n",
      "Think of girl, constantly\n",
      "On that ship, I dream she's there\n",
      "I smell the rose in her hair.\n",
      "Louie Louie, oh no\n",
      "Me gotta go\n",
      "Aye-yi-yi-yi, I said\n",
      "Louie Louie, oh baby\n",
      "Me gotta go\n",
      "Okay, let's give it to 'em, right now!\n",
      "See Jamaica, the moon above\n",
      "It won't be long, me see me love\n",
      "Take her in my arms again\n",
      "I tell her I'll never leave again\n",
      "Louie Louie, oh no\n",
      "Me gotta go\n",
      "Aye-yi-yi-yi, I said\n",
      "Louie Louie, oh baby\n",
      "Me gotta go\n",
      "I said we gotta go now\n",
      "Let's take it on outta here now\n",
      "Let's go!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "louielist=louielouie.split(\"\\ \")\t\t# lists are your Python Friend. (One of them, at least)\n",
    "print(louielouie)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "You could also read this file line by line with readline().  For example, to get the file contents into louie a string variable (and assuming that the file has been closed and opened again after the foregoing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "louie=\"\"\t# string var where we're going to put the lines from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    line=kingsMenLouie.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    louie+=line\n",
    "louie==louielouie"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Give the above code a try to see what you get.  Are louie and louielouie different?  Try the command louie==louielouie.  \n",
    "\n",
    "Python usually does a good job closing files that have been opened, but it's good practice to do so explicitly whenever possible.  This is expecially true when you are writing data out to a  file, as explicitly closing a file written to forces any remaining write operation to finish.  Did you close all the files you opened, above?\n",
    "\n",
    "A simple way to close a file you've written to is as follows.  Suppose you want to write the character string iLikeButter to a file called greaseitup.txt in your current directory.  If you do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('greaseitup.txt','wt') as butterOut: \n",
    "    butterOut.write(iLikeButter)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the file will be closed automatically for you when your write operation is completed.  Note the 'wt' in the open statement.  't' is for text, but it's optional.  if you include a 'b' instead, you'll have a binary file instead of a text file.\n",
    "\n",
    "The procedures for reading and writing binary files using open, .read, etc. are for the most part the same as for text files, and so we're not going to spend time here on binary file input and output.  We're shortly going to move on to reading and writing csv files, but before that let's take a look at the classic method for “serializing” (storing with permanency) python objects called pickling.  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A python object might need to be written/read in binary representation/format into/from file for further/later processing. To do so, we need to import the pickle package:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now let's pickle our louielist from above in a file in the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(louielist,open('louielist.p','wb'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The above writes a binary pickle file.  You can read the file back into Python like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "louielsBack=pickle.load(open('louielist.p','rb'))\n",
    "louielist==louielsBack"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Did you get louielist back unchanged?  Try louielist == louielsBack from the command prompt.\n",
    "\n",
    "We're going to move ahead to consider csv files, but to do so we're going to make use of the pandas package.  So let's import pandas first, and then look at a simple example of a very useful panda object, the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\t# panda's nickname is pd\n",
    "\n",
    "import numpy as np\t# numpy as np\n",
    "\n",
    "from pandas import DataFrame, Series\t    # for convenience\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "My guess is that you have used the numpy package before in your work or in a previous course.   DataFrame and Series are very handy pandas data structures that can do yeoman work for you in your data management efforts.\n",
    "\n",
    "By way of introduction, let's first read a little pickled pandas DataFrame.  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A pandas DataFrame is a table-like data structure with columns that can be of different data types, and that has both row and column indices. \n",
    "\n",
    "A Series is like one column of a DataFrame. It's a kind of vector that has an associated index.  A DataFrame can be thought of as a set of Series in the columns that share a single index, the row index.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "DataFrames and Series have many useful attributes and features, some of which we'll explore in upcoming exercises.  But now let's try reading a less trivial csv file into a DataFrame.  The file is xyzcust10.csv, and it should be available to you on Canvas.  Take a look at it with your favorite text editor.  Then, put it in a place you can find it from Canvas, and input it into a DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzcust10=pd.read_csv('xyzcust10.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The file has 10 variables in it.  The rows, or records, are XYZ customers.  How many records are in xyzcust10?\n",
    "\n",
    "What types of variables are in the columns of xyzcust10? To find out:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCTNO                    object\n",
      "ZIP                        int64\n",
      "ZIP4                       int64\n",
      "LTD_SALES                float64\n",
      "LTD_TRANSACTIONS           int64\n",
      "YTD_SALES_2009           float64\n",
      "YTD_TRANSACTIONS_2009      int64\n",
      "CHANNEL_ACQUISITION       object\n",
      "BUYER_STATUS              object\n",
      "ZIP9_Supercode             int64\n",
      "ZIP9_SUPERCODE             int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30471"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xyzcust10.dtypes)\n",
    "\n",
    "len(xyzcust10.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Look at the first and last rows in xyzcust10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ZIP4</th>\n",
       "      <th>LTD_SALES</th>\n",
       "      <th>LTD_TRANSACTIONS</th>\n",
       "      <th>YTD_SALES_2009</th>\n",
       "      <th>YTD_TRANSACTIONS_2009</th>\n",
       "      <th>CHANNEL_ACQUISITION</th>\n",
       "      <th>BUYER_STATUS</th>\n",
       "      <th>ZIP9_Supercode</th>\n",
       "      <th>ZIP9_SUPERCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WDQQLLDQL</td>\n",
       "      <td>60084</td>\n",
       "      <td>5016</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>IB</td>\n",
       "      <td>INACTIVE</td>\n",
       "      <td>600845016</td>\n",
       "      <td>600845016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ACCTNO    ZIP  ZIP4  LTD_SALES  LTD_TRANSACTIONS  YTD_SALES_2009  \\\n",
       "0  WDQQLLDQL  60084  5016       90.0                 1             0.0   \n",
       "\n",
       "   YTD_TRANSACTIONS_2009 CHANNEL_ACQUISITION BUYER_STATUS  ZIP9_Supercode  \\\n",
       "0                      0                  IB     INACTIVE       600845016   \n",
       "\n",
       "   ZIP9_SUPERCODE  \n",
       "0       600845016  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyzcust10.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCTNO</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ZIP4</th>\n",
       "      <th>LTD_SALES</th>\n",
       "      <th>LTD_TRANSACTIONS</th>\n",
       "      <th>YTD_SALES_2009</th>\n",
       "      <th>YTD_TRANSACTIONS_2009</th>\n",
       "      <th>CHANNEL_ACQUISITION</th>\n",
       "      <th>BUYER_STATUS</th>\n",
       "      <th>ZIP9_Supercode</th>\n",
       "      <th>ZIP9_SUPERCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30470</th>\n",
       "      <td>SQQHDYHWH</td>\n",
       "      <td>60098</td>\n",
       "      <td>4160</td>\n",
       "      <td>4527.0</td>\n",
       "      <td>16</td>\n",
       "      <td>672.0</td>\n",
       "      <td>2</td>\n",
       "      <td>RT</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>600984160</td>\n",
       "      <td>600984160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACCTNO    ZIP  ZIP4  LTD_SALES  LTD_TRANSACTIONS  YTD_SALES_2009  \\\n",
       "30470  SQQHDYHWH  60098  4160     4527.0                16           672.0   \n",
       "\n",
       "       YTD_TRANSACTIONS_2009 CHANNEL_ACQUISITION BUYER_STATUS  ZIP9_Supercode  \\\n",
       "30470                      2                  RT       ACTIVE       600984160   \n",
       "\n",
       "       ZIP9_SUPERCODE  \n",
       "30470       600984160  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyzcust10.tail(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that in this file missing values for ZIP, ZIP4, and the nine digit ZIP are represented with zeros, “0's.”  The ZIPs could really also be coded as strings, rather than as integers, couldn't they?  Also, it looks like there might be two nine digit ZIP code variables.  Are they the same? \n",
    "\n",
    "That is are the values in these two variables the same for every row of data?  How would you locate the rows in xyzcust10 that have a zero for ZIP or for ZIP4?  We'll see in the next session's Python Practice.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements :\n",
    "1. Produce a list of Zip values in xyzcust10 along with their frequencies\n",
    "2. How many records with missing ZIP in xyzcust10?\n",
    "3. How many active and inactive BUYER_STATUS in xyzcust10?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP\n",
       "0           1\n",
       "60056    1529\n",
       "60060    1296\n",
       "60061    1207\n",
       "60062    3099\n",
       "60064      42\n",
       "60065      21\n",
       "60067    3050\n",
       "60068    2781\n",
       "60069     784\n",
       "60070     463\n",
       "60071      98\n",
       "60072      34\n",
       "60073     686\n",
       "60074    1313\n",
       "60075       5\n",
       "60076    1090\n",
       "60077     740\n",
       "60078      25\n",
       "60079       2\n",
       "60081     322\n",
       "60082       3\n",
       "60083     344\n",
       "60084     723\n",
       "60085     379\n",
       "60087     268\n",
       "60088      28\n",
       "60089    2007\n",
       "60090     648\n",
       "60091    3458\n",
       "60093    3178\n",
       "60094       4\n",
       "60095       1\n",
       "60096     125\n",
       "60097     151\n",
       "60098     564\n",
       "60192       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your python code that meets the above requirements in this cell\n",
    "\n",
    "#Count of values and frequencies in the ZIP column\n",
    "xyzcust10.groupby('ZIP').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP4\n",
       "0       3638\n",
       "3          2\n",
       "4          1\n",
       "6          1\n",
       "7          2\n",
       "10         1\n",
       "20         1\n",
       "24         1\n",
       "33         1\n",
       "41         1\n",
       "45         1\n",
       "54         1\n",
       "66         1\n",
       "68         2\n",
       "70         1\n",
       "84         1\n",
       "97         1\n",
       "102        1\n",
       "103        1\n",
       "116        1\n",
       "121        1\n",
       "125        1\n",
       "127        1\n",
       "128        1\n",
       "129        1\n",
       "133        1\n",
       "136        1\n",
       "137        1\n",
       "142        1\n",
       "146        1\n",
       "        ... \n",
       "9752       2\n",
       "9755       3\n",
       "9756       1\n",
       "9757       2\n",
       "9758       1\n",
       "9759       1\n",
       "9762       2\n",
       "9763       1\n",
       "9765       2\n",
       "9766       5\n",
       "9767       2\n",
       "9768       2\n",
       "9772       1\n",
       "9775       4\n",
       "9776       3\n",
       "9778       1\n",
       "9779       1\n",
       "9781       1\n",
       "9784       1\n",
       "9787       1\n",
       "9788       4\n",
       "9791       3\n",
       "9792       1\n",
       "9793       4\n",
       "9794       2\n",
       "9795       1\n",
       "9797       1\n",
       "9798       1\n",
       "9945       1\n",
       "9999       4\n",
       "Length: 6391, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of values and frequencies in the ZIP4 column\n",
    "xyzcust10.groupby('ZIP4').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP9_Supercode\n",
       "60056         3\n",
       "60060         7\n",
       "60061         4\n",
       "60062        31\n",
       "60064         2\n",
       "60067        10\n",
       "60068         5\n",
       "60069        10\n",
       "60070         1\n",
       "60073         4\n",
       "60074         3\n",
       "60076         3\n",
       "60077         3\n",
       "60081         2\n",
       "60083         2\n",
       "60084         2\n",
       "60085         5\n",
       "60087         4\n",
       "60089         4\n",
       "60090         2\n",
       "60091        10\n",
       "60093        11\n",
       "60096         3\n",
       "60097         2\n",
       "60098         2\n",
       "600560129     1\n",
       "600560214     1\n",
       "600560390     1\n",
       "600560414     1\n",
       "600560447     1\n",
       "             ..\n",
       "600989224     1\n",
       "600989237     1\n",
       "600989243     2\n",
       "600989258     1\n",
       "600989420     1\n",
       "600989422     3\n",
       "600989423     1\n",
       "600989446     1\n",
       "600989511     1\n",
       "600989516     1\n",
       "600989553     1\n",
       "600989607     1\n",
       "600989608     1\n",
       "600989611     2\n",
       "600989612     1\n",
       "600989614     1\n",
       "600989616     1\n",
       "600989618     1\n",
       "600989630     1\n",
       "600989661     2\n",
       "600989678     1\n",
       "600989681     1\n",
       "600989684     1\n",
       "600989686     1\n",
       "600989725     1\n",
       "600989729     1\n",
       "600989755     1\n",
       "600989765     1\n",
       "600989768     1\n",
       "600989769     1\n",
       "Length: 16918, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of values and frequencies in the ZIP9_Supercode column\n",
    "xyzcust10.groupby('ZIP9_Supercode').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZIP9_SUPERCODE\n",
       "60056         3\n",
       "60060         7\n",
       "60061         4\n",
       "60062        31\n",
       "60064         2\n",
       "60067        10\n",
       "60068         5\n",
       "60069        10\n",
       "60070         1\n",
       "60073         4\n",
       "60074         3\n",
       "60076         3\n",
       "60077         3\n",
       "60081         2\n",
       "60083         2\n",
       "60084         2\n",
       "60085         5\n",
       "60087         4\n",
       "60089         4\n",
       "60090         2\n",
       "60091        10\n",
       "60093        11\n",
       "60096         3\n",
       "60097         2\n",
       "60098         2\n",
       "600560129     1\n",
       "600560214     1\n",
       "600560390     1\n",
       "600560414     1\n",
       "600560447     1\n",
       "             ..\n",
       "600989224     1\n",
       "600989237     1\n",
       "600989243     2\n",
       "600989258     1\n",
       "600989420     1\n",
       "600989422     3\n",
       "600989423     1\n",
       "600989446     1\n",
       "600989511     1\n",
       "600989516     1\n",
       "600989553     1\n",
       "600989607     1\n",
       "600989608     1\n",
       "600989611     2\n",
       "600989612     1\n",
       "600989614     1\n",
       "600989616     1\n",
       "600989618     1\n",
       "600989630     1\n",
       "600989661     2\n",
       "600989678     1\n",
       "600989681     1\n",
       "600989684     1\n",
       "600989686     1\n",
       "600989725     1\n",
       "600989729     1\n",
       "600989755     1\n",
       "600989765     1\n",
       "600989768     1\n",
       "600989769     1\n",
       "Length: 16918, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count of values and frequencies in the ZIP9_SUPERCODE column\n",
    "xyzcust10.groupby('ZIP9_SUPERCODE').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 records with missing ZIP data.\n",
      "There are 3638 records with missing ZIP4 data.\n",
      "There are 0 records with missing ZIP9_Supercode data.\n",
      "There are 0 records with missing ZIP9_SUPERCODE data.\n",
      "There are 3639 total zip values missing across all four columns containing zip data.\n"
     ]
    }
   ],
   "source": [
    "#Missing records in ZIP column\n",
    "missing_zip=xyzcust10.query('ZIP == 0').ZIP.count()\n",
    "print(\"There are {} records with missing ZIP data.\".format(missing_zip))\n",
    "#Missing records in ZIP4 column\n",
    "missing_zip_four=xyzcust10.query('ZIP4 == 0').ZIP4.count()\n",
    "print(\"There are {} records with missing ZIP4 data.\".format(missing_zip_four))\n",
    "#Missing records in ZIP9_Supercode column\n",
    "missing_zip_nine_super=xyzcust10.query('ZIP9_Supercode == 0').ZIP9_Supercode.count()\n",
    "print(\"There are {} records with missing ZIP9_Supercode data.\".format(missing_zip_nine_super))\n",
    "#Missing records in ZIP9_SUPERCODE column\n",
    "missing_zip_nine_super_caps=xyzcust10.query('ZIP9_SUPERCODE == 0').ZIP9_SUPERCODE.count()\n",
    "print(\"There are {} records with missing ZIP9_SUPERCODE data.\".format(missing_zip_nine_super_caps))\n",
    "total_missing_records = missing_zip + missing_zip_four + missing_zip_nine_super + missing_zip_nine_super_caps\n",
    "print(\"There are {} total zip values missing across all four columns containing zip data.\".format(total_missing_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13465 records with active buyer status.\n",
      "There are 9078 records with inactive buyer status.\n"
     ]
    }
   ],
   "source": [
    "#Active BUYER_STATUS count\n",
    "active_status=xyzcust10.query('BUYER_STATUS ==\"ACTIVE\"').BUYER_STATUS.count()\n",
    "print(\"There are {} records with active buyer status.\".format(active_status))\n",
    "#Inactive BUYER_STATUS count \n",
    "inactive_status=xyzcust10.query('BUYER_STATUS ==\"INACTIVE\"').BUYER_STATUS.count()\n",
    "print(\"There are {} records with inactive buyer status.\".format(inactive_status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
